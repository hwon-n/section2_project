{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_guide.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8Vak1n4x/eRwZMiFCr4Mu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwon-n/section2_project/blob/main/Project_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wjlH5Hpzdrh"
      },
      "source": [
        "# Section2 Project\n",
        "\n",
        "## 데이터 선택 이유는?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhmwHS5dL3rZ"
      },
      "source": [
        "## 데이터 전처리\n",
        "\n",
        "1) Age\n",
        "\n",
        " 30대 미만 / 30대/ 4-50대 / 60대 ~\n",
        " 총 네 그룹으로 나눠서 OrdinalEncoder로 mapping 해주기\n",
        "\n",
        " 2) STATE\n",
        "\n",
        " STATE.unique()로 값들을 살펴보니 인도의 지역명이었고, 대부분의 지역들이 북부 쪽에 위치해있었다. 때문에 북부에 위치한 지역이 경우 1을 아닌 경우는 0을 return 해서 TargetEncoder로 인코딩 하기로 결정했다. \n",
        "\n",
        "\n",
        " 3) Experience\n",
        "\n",
        " Experience가 2년 이하면 Entry, 2 ~ 5년 사이면 Intermediate, 5 ~ 10년 사이면 Mid 그리고 그 이상이면 Senior로 그룹을 나눠줬다. 그리고 후에 Entry에 1, Intermediate에 2, Mid에 3, Senior에 4를 mapping 해줬다.\n",
        "\n",
        " 4) ID, CITY\n",
        " ID는 모델을 학습하는데에 있어서 필요없는 값이라 제거해줬다. 또한 CITY는 너무 많은 범주를 가지고 있어서 모델이 학습하는데 일반화가 잘 안될것 같아서 제거해줬다. \n",
        "\n",
        " 5) Income\n",
        " 우선 MinMaxScaler로 0.0 ~ 1.0 사이로 스케일링 해준 뒤 label을 사용해 pd.cut으로 라벨링을 해 준뒤 OrdinalEncoder로 Low, Mid, High로 인코딩 해줬다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu9HWsl199dN"
      },
      "source": [
        "## 모델 학습\n",
        "\n",
        "### 1) Logistic Regression\n",
        "\n",
        "Training score: 0.8769\n",
        "\n",
        "Validation score: 0.8770\n",
        "\n",
        "MAE: 0.12299\n",
        "\n",
        "R2: -0.140\n",
        "\n",
        "원래 R2 값은 0과 1 사이의 값을 가지는데 음수가 나왔으므로 해당 모델은 성능이 떨어지는 것을 의미함.\n",
        "\n",
        "### 2) Decision Tree\n",
        "\n",
        "Validation score: 0.88075\n",
        "\n",
        "ROC AUC score: 0.698741\n",
        "\n",
        "f1 score: 0.48544\n",
        "\n",
        "precision/recall: (0 - 0.93 / 0.94), (1 - 0.52 / 0.46)\n",
        "\n",
        "### 3) RandomForest (Tree Ensemble)\n",
        "Validation score: 0.088789\n",
        "\n",
        "ROC AUC score: 0.70359\n",
        "\n",
        "f1 score: 0.50187\n",
        "\n",
        "precision/recall : (0 - 0.93/0.95) , (1 - 0.55/0.46)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IctMlKlQLEK3"
      },
      "source": [
        "## 최종 모델 결정\n",
        "\n",
        "Logistic Regression의 R2 score를 보면 음수가 나왔으므로 이 데이터에 Logistic Regression을 사용하는 것은 적합하지 않다는 판단이 들어 Logistic Regression을 제외했습니다.\n",
        "\n",
        "또한, Decision Tree와 RandomForest를 비교했을 때, 둘의 Validation score가 비슷하지만 Randomforest쪽이 ROC AUC score와 f1 score가 더 높으므로 Decision tree보다 Randomforest 모델이 제가 사용하려는 데이터에 적합하다는 결론이 내려져 최종 모델은 \"RandomForest\"로 결정했습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "panGT6LYLyDX"
      },
      "source": [
        "## 하이퍼파라미터 튜닝\n",
        "\n",
        "Decision Tree나 Randomforest를 보면 모두 과적합이므로 최대한 과적합을 제어해주기 위해서 트리의 노드를 정하는 최대 특성의 수를 qrt 해줬고, 리프 노드의 최소 수를 5개로 제한해주었다. (최소 수가 커질수록 과적합 위험이 높아짐)\n",
        "\n",
        "또한 target이 불균형 클래스이므로 class_weight을 balanced로 제한해줬다. \n",
        "기존에는 총 100개의 모델을 만들어서 최종적으로 결론을 냈지만, 200개의 모델로 늘려서 다양한 결과를 도출하고 이를 바탕으로 결론을 낼 수 있도록 했다. \n",
        "\n",
        "\n",
        "그 결과 validation 검증 정확도는 0.8576으로 낮아졌지만 ROC AUC score는 0.83629로, f1 score는 0.58262로 올랐다.\n",
        "\n",
        "그래서 test dataset에도 최종적으로 검증을 해봤는데, test 검증 정확도는 0.85670이고 ROC AUC score는 0.83023, f1 score는 0.57716으로 나쁘지 않은 성적을 보여줬다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGdF4xlfN2gZ"
      },
      "source": [
        "## 모델 시각화\n",
        "\n",
        "### PermutationImportance\n",
        "\n",
        "모델의 성능을 저하시키는 특성이 있으면 제외하려고 Permutation Importance를 시행했는데 다행스럽게도 낮은 score는 있었지만 음수를 가진 score는 없었기 때문에 추가적인 feature engineering은 하지 않아도 됐다.\n",
        "\n"
      ]
    }
  ]
}